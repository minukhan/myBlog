
### 캐시 메모리 및 메모리 계층성

- 보통 컴퓨터 시스템에서 속도가 빠를수록 용량이 작고 가격이 비쌈
- 속도가 느릴수록 용량이 크고 가격이 저렴함.

- 이거 두개를 계층적으로 구성하는 방식을 메모리 계층성이라고 한다.

##### 왜 쓸까?
- CPU와 주 메모리간의 속도 차이를 극복, 시스템 전체의 성능을 향상시키기 위한 핵심적인 원리.

##### 그냥 돈 많으면 빠른거 다 때려넣으면 되는거아닌가?

- 제한된 공간
	- 빠른거가 크기가 크다고함. 그래서 많이 넣으면 물리적으로 불가능.
	- CPU 칩 내부에 많은 공간을 차지하도록 넣을 수 없음.
- 높은 발열 및 전력소모
	- 속도 빠른것들만 넣어놓으면 터질 수 있음. 발열이 심하다고함. 

>[!note] 정리
>
>그냥 빠른것만 넣으면 되는 줄 알았더니, 그냥 돈 아낄려고 이렇게 하는줄 알았더니 물리적인 문제도 있었다.


### L1, L2 캐시

##### L1 캐시 (Level 1 Cache)
- 가장 빠르고 가장 작다.
- CPU 코어마다 전용으로 존재.
- 가장 최근에 사용된 데이터를 저장한다.

##### L2 캐시
- L1 캐시보다 느리지만 용량이 더 크다.
- CPU 코어마다 전용으로 존재하거나 여러 코어가 공유할 수 있다. 

### 캐시에 올라오는 데이터 관리

- 캐시 메모리는 캐시 라인이라는 고정된 크기 단위로 데이터를 저장하고 관리한다. 

##### 캐시 라인이란?

- **캐시 메모리는 주 메모리의 데이터를 일정 단위로 가져와 저장**
- 이 단위를 **캐시 라인**이라고 부름
- 일반적으로 **64바이트** 정도 크기

> 즉, CPU가 메모리에서 어떤 데이터 한 개를 가져올 때 지역성을 활용하려고 근처에 있는거까지 가져오려고 블럭으로 가져오는 것. 


### 캐시간의 동기화는 어떻게 이루어져?

- 멀티코어 시스템에서 각 코어는 자신만의 캐시 (L1, L2) 를 가진다고 함.
- 공유메모리에 대한 데이터 일관성 유지를 위해서 캐시 코히어런스 프로토콜이 사용된다. 


##### 대표적인 캐시 코히어런스 방식

##### Snooping Protocol (엿듣기 방식)

- 각 코어의 캐시가 버스를 통해서 다른 캐시의 쓰기 작업을 감시한다(Snoop)

### 기본 구조

- 멀티코어 CPU에서 **각 코어는 자신만의 캐시**(L1, L2 등)를 가짐
- 코어들의 캐시는 **공유 버스(Bus)**를 통해 서로 “엿볼 수 있는 통로”로 연결되어 있음

### 데이터 변경 시 흐름 (Snooping Protocol 기준)

1. **CPU 1**에서 캐시 라인 X를 **수정**
2. 이 변경 사실이 **버스를 통해 흘러감**
3. **CPU 2**는 같은 캐시 라인 X를 가지고 있다면
    - 버스 신호를 **엿보고(snoop)**
    - 자신의 캐시를 **무효화(invalidate)하거나 갱신(update)**
4. **CPU 3**은 해당 데이터를 캐시에 가지고 있지 않으면 → 무시, 메모리에서 읽으면 항상 최신값 확보

### 핵심 포인트

- **각 캐시는 능동적으로 버스를 감시** → “엿듣기(Snooping)”
- **같은 데이터를 가진 캐시만 반응** → 불필요한 캐시 변경 방지
- 결과적으로 **모든 코어에서 데이터 일관성 유지**


### 캐시 메모리 어디에 저장할지는 어떻게 정해??  (Mapping 방식)

- 주 메모리 블록을 캐시의 어느 위치에 저장할지 결정하는 방식은 3가지가 있다. 

##### Direct Mapping 

- 주 메모리 블록이 캐시의 특정 위치에만 저장될 수 있도록 미리 정해져 있다. 
- 간단하지만 충돌이 잦아 캐시 히트율이 낮음. 

##### Fully Associative Mapping

- 주 메모리 블록이 캐시의 어떤 위치에도 저장될 수 있다. 
- 유연하지만 하드웨어 구현이 복잡하고 비용이 많이 듬. 

##### Set-Associative Mapping

- 위 두 방식 절충안으로, 캐시를 여러개의 집합으로 나누고, 주 메모리 블록이 특정 집합 내의 아무 위치에나 저장될 수 있다. 

- **Direct:** 주차장에 차를 **딱 한 칸만 지정**
- **Fully Associative:** 주차장 **어느 칸에나 가능**
- **Set-Associative:** 주차장 **구역이 정해져 있고, 구역 안에서는 자유롭게 주차**


### 캐시 메모리 빠른곳에 잘 넣어야하는거아니야? 이렇게 랜덤으로 넣어?

- 캐시 매핑은 어떤 위치에 데이터를 놓을지만 정하는것. (착각하기 쉬운듯) 
- 그니까 캐시 메모리에서 어떤 공간을 데이터 저장 공간으로 사용할지 결정하는 과정임
- 이제 어떤 캐시에 어떤 데이터가 들어갈지는 나중에 알고리즘으로 저장. 


### 캐시의 지역성

- 지역성
	- 데이터 접근 패턴이 시간에 따라 일정하다는 것. 

- 시간 지역성 
	- 최근에 접근한 데이터는 가까운 미래에 다시 접근될 가능성이 높다. 
- 공간 지역성
	- 접근한 데이터의 주변 데이터도 곧 접근될 가능성이 높다. 


### 2차원 배열 탐색의 성능 차이 

- 보통 가로 방향으로 탐색할때가 훨씬 성능이 좋다. -> 공간지역성 개념이 들어감. 

- 자바, C, C++ 같은 언어에서 2차원 배열은 메모리상에 행 우선으로 저장된다.
- 행끼리 모여서 저장되는 것. 그래서 공간지역성을 최대로 활용해서 캐시라인을 가져오면 히트율이 증가.  -> 빠름.
- 그러나 세로는 멀리 떨어져있기 떄문에 캐시 미스가 빈번하게 발생해서 느리다. 


### 캐시의 공간 지역성 구현. 

- 캐시는 라인 단위로 데이터를 저장하고 관리해서 공간 지역성을 구현한다. 
- 주 메모리 특정 주소에 접근할 때, 그 주변의 연속적인 데이터를 가져옴. (캐시 라인) 블럭으로 가져옴. 
- 다음에 접근할 데이터가 주변에 있다면 캐시 히트 -> 성능이 높아진다. 
