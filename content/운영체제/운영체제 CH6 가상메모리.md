
## 1. 가상 메모리

OS 역할 -> 메모리 할당
- 프로그램이 CPU에서 실행되려면 실행에 당장 필요한 부분이 메모리에 올라와 있어야 한다.
    - **그리고 현대 운영체제는 여러 프로세스를 한번에 동작시키는데, 이때 어떤 프로그램에게 어느 정도의 메모리를 할당할 것인가에 대한 문제에 직면**

스왑 영역
- 프로그램이 실행되기 위해 프로세스의 주소 공간 전체가 메모리에 올라와야한다면 실행 가능한 프로세스의 개수는 한계가 존재 -> 심지어 물리적 메모리보다 큰 프로그램은 실행 X
- **다행히 운영체제는 CPU에서 당장 수행해야 할 부분만을 메모리에 올려놓고 그렇지 않은 부분은 디스크의 스왑 영역에 내려놓았다가 다시 필요해지면 메모리에 올라가 있는 부분과 교체하는 방식을 사용함**

물리적 메모리에 대해서 프로그램이 직접 고려하지 않도록 운영체제가 지원
- 스왑 영역 활용하여 프로그램 입장에선 물리적 메모리 크기에 대한 제약을 생각하지 않아도 됨
- 운영체제는 프로그램이 물리적 메모리를 고려할 필요 없이 자기 자신만이 메모리를 사용하는 것처럼 가정해 프로그래밍하는 것을 지원 -> 이것이 가상 메모리

**가상메모리**
- 이렇게 프로그램은 **0번지부터 시작하는 자기 자신만의 메모리 주소 공간을 가정할 수 있는데, 이러한 메모리 공간을 가상 메모리**라고 부름
- 즉, **프로세스마다 각각 0번지부터의 주소 공간을 가지게 되며, 이들 공간 중 일부는 물리적 메모리에 적재되고 일부는 디스크의 스왑 영역에 존재하게 됨** -> 아까 말한 스와핑

프로세스의 주소 공간을 메모리에 적재하는 단위에 따라 가상메모리 기법 두 가지로 나뉨
- *요구 페이징 방식*
- 요구 세그먼테이션 방식

현존하는 방식은 요구 페이징 방식밖에 없기 때문에, 요구 페이징 방식에 대해서만 설명하겠다


## 2. 요구 페이징

#### 요구 페이징
: 프로그램 실행 시 프로세스 구성하는 모든 페이지 한꺼번에 메모리에 올리지 않고
**당장 사용될 페이지만**을 올리는 방식
- 특정 페이지에 대해 CPU의 요청이 들어온 후에야 해당 페이지를 메모리에 올림
- 프로세스가 실행되는 동안 일부 페이지만 메모리에 올리고 나머지 페이지는 디스크의 스왑 영역에 존재하게 됨

장점
- 당장 실행에 필요한 페이지만을 메모리에 적재하므로 메모리 사용량 감소
- 메모리에 프로세스 전체를 올리는 데 소용되는 I/O 오버헤드도 줄어듦
	- 사용되지 않을 주소 영역에 대한 입출력까지 수행하던 기존 방식에 비해 응답시간을 단축시킬 수 있으며, 시스템이 더 많은 프로세스를 수용할 수 있게 해줌
- 프로그램이 **물리적 메모리의 용량 제약을 벗어날 수 있게 해줌**

#### 유효-무효 비트 (valid-invalid bit)
![](https://i.imgur.com/4OM21au.png)

- 요구 페이징에는 유효-무효 비트를 두어 각 페이지가 메모리에 존재하는지 표시함
	- v값이면 실제 물리적 메모리에 올라와있다는 의미
    - i값이면 물리적 메모리에 올라와있지 않다는 것이거나, 해당 페이지가 메모리에 올라와 있지 않고 swap area에 있는 경우
- 프로세스 실행 전에는 모든 페이지의 비트가 무효값으로 초기화
- 특정 페이지가 참조되어 메모리에 적재되면 해당 페이지 비트는 유효값으로 변경됨
- 그 후, 메모리 적재되어있던 페이지가 디스크의 스왑 영역으로 쫓겨날 때에는 비트가 다시 무효값을 가지게 됨

- 이 유효-무효 비트는 각 프로세스를 구성하는 모든 페이지에 대해 존재해야하므로, **페이지 테이블의 각 항목별로 저장됨**

#### 페이지 부재 (Page fault)
CPU가 어떤 페이지를 참조하려 하는데, 현재 메모리에 올라와있지 않아 유효-무효 비트가 무효로 세팅되어있는 경우 '페이지 부재'가 일어났다고 함

##### 페이징 부재 처리
![](https://i.imgur.com/bMHvbYR.png)

- CPU가 무효 페이지에 접근하면 주소 변환 담당 하드웨어 MMU가 페이지 부재 트랩(page fault trap) 발생시킴
- CPU 제어권이 커널모드로 전환 -> 운영체제의 페이지 부래 처리 루틴이 호출되어 페이지 부재 처리됨
- 페이지 부재 처리 순서
	1. CPU가 페이지 N을 참조
	2. 페이지 테이블에서 페이지 N이 무효 상태임을 확인
	3. 페이지 부재트랩 발생
	4. 디스크에서 부재 페이지를 빈 프레임으로 적재하고 페이지 테이블 업데이트함

#### 요구 페이징의 성능
- 요구페이징 기법 성능에 가장 큰 영향 미치는 요소 = 페이지 부재의 발생 빈도
- 페이지 부재 일어나면 요청된 페이지를 디스크로부터 메모리에 읽어오는 막대한 오버헤드 발생하기 때문에 최대한 안 일어나는게 좋음 (당연함)

## 3. 페이지 교체

#### 페이지 교체
![](https://i.imgur.com/qajoKMD.png)

페이지 교체는 언제 발생?
- 메모리에 빈 프레임이 존재하지 않을 경우 발생함
	- 페이지 부재가 발생하면 요청된 페이지를 디스크에서 메모리로 읽어와야함 (오버헤드 발생)
	- 이때 물리적 메모리에 빈 프레임이 존재하지 않을 수 있음
	- 이 경우 **메모리에 올라와 있는 페이지 중 하나를 디스크로 쫓아내 메모리에 빈 공간을 확보하는 작업** 필요
	- 이것이 페이지 교체

### 페이지 교체 알고리즘

**페이지 교체 알고리즘**
페이지 교체가 발생하고, 어떤 프레임에 있는 페이지를 쫓아낼 것인지 결정하는 알고리즘
알고리즘의 목표 = 페이지 부재율을 최소하는 것

**페이지 교체 알고리즘 성능 평가 방법**
- 주어진 페이지 참조열에 대해 페이지 부재율을 계산함으로써 평가할 수 있음
	- 페이지 참조열 : 참조되는 페이지들의 번호를 시간 순서에 따라 나열한 것
	- 해당 번호의 페이지가 메모리에 올라와 있으면 메모리에 hit되었다고 함
	- 메모리에 없는 경우 페이지 부재가 발생했다고 함

|용어|의미|
|---|---|
|**페이지 참조열**|시간 순서대로 페이지 접근 기록 (예: `1, 2, 3, 2, 4, 1, 5...`)|
|**페이지 부재 (Page Fault)**|접근하려는 페이지가 메모리에 없을 때 발생|
|**페이지 부재율**|`Page Fault 횟수 / 전체 페이지 접근 횟수`|

#### 알고리즘

1. 최적 페이지 교체 (Optimal)
	- 상한을 정하기 위해서 이게 최고의 알고리즘이므로 이게 만점의 기준이 됨
	- 페이지 부재율을 가장 최소화하기 위해선 가장 먼 미래에 참조될 페이지를 쫓아내면 된다는 알고리즘
	- 문제는 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 안다는 전제 하에 사용가능하므로 실제 운영체제에서는 사용 X
	- 그저 최적의 알고리즘
2. 선입선출 알고리즘 (FIFO)
	- 가장 먼저 올라온 페이지를 우선적으로 내쫓는 알고리즘
	- 물리적 메모리를 증가시켰을 때 페이지 부재율이 오히려 늘어날 수도 있다는 단점이 있음 -> 일단 나중에 찾아볼게요 (뭔가 문제가 있어보임)
3. LRU (Least Recently Used) 알고리즘 -> ubuntu
	- 마지막 참조 시점이 가장 오래된 페이지를 교체하는 알고리즘
	- 계속 안 불리던 애를 교체시킴
4. LFU (Least Frequently Used) 알고리즘
	- 페이지의 참조 횟수로 교체 페이지를 결정하는 알고리즘
	- 과거에 참조 횟수가 **가장 적었던 페이지** 내쫓고 그 자리에 새로 참조될 페이지 적재함
5. 클럭 (Clock) 알고리즘
	- LRU, LFU 모두 페이지의 참조 시각 및 참조 횟수를 소프트웨어적으로 유지하고 비교해야 하므로 알고리즘 운영에 오버헤드가 발생
		- 클럭 알고리즘은 하드웨어적인 지원을 통해 이와 같은 알고리즘의 운영 오버헤드를 줄인 방식
	- 클럭 알고리즘은 LRU를 근사시킨 알고리즘으로 NUR (Not Used Recently)알고리즘이라고 불리움
		- LRU와 반대로 가장 오래된 참조된 페이지를 교체하는 것이 아닌, 오랫동안 참조되지 않은 페이지 중 하나를 교체함
		- 즉, LRU와 유사하지만 교체되는 페이지의 참조 시점이 가장 오래되었다는 것을 보장하진 못한다는 점에서 **LRU를 근사시킨 알고리즘**


## 4. 페이지 프레임의 할당

프로세스 여러 개가 동시에 수행되는 상황에서는 각 프로세스에 얼마만큼의 메모리 공간을 할당할지 고려해야 함
- 프로그램별로 페이지 할당 안 해주면 메모리에 특정 프로세스가 페이지 프레임 장악하는 현상 발생할 수 있음
- 이를 방지하기 위해 각각의 프로그램마다 필요로하는 페이지 할당해줘서 페이지 부재 적게 나도록 해줘야함

**페이지 프레임 할당 방식**
- 균등할당
	- 모든 프로세스에 동일한 개수 할당
	- 어떤 페이지는 많이 어떤 페이지는 적게 필요한데 다 동일하므로 비효율적
- 비례할당
	- 프로세스 크기에 비례하여 할당
	- 같은 프로세스라도 시간에 따라 필요한 페이지가 다를 수 있다는 문제 존재
- 우선순위 할당
	- 프로세스의 우선순위에 따라 할당
	- CPU 우선순위 높은 프로세스에게 페이지 더 많이 할당해줌

> 3방식 다 비효율적일 수도 있음 -> 각 프로세스별로 일정 수준의 페이지 프레임 할당 필수


## 5. 전역교체와 지역교체

페이지 교체시 교체 대상이 될 프레임의 범위에 따라 전역과 지역으로 나뉨

#### 전역 교체
- 모든 페이지 프레임이 교체 대상이 되는 방안
- 프로세스마다 페이지 프레임을 미리 할당하지 않고, 전체 메모리를 각 프로세스가 공유해서 교체 알고리즘에 근거해서 할당되는 메모리 양을 가변적으로 교체
    - 즉, 교체 대상 페이지가 어떤 프로세스에 속한 것인지는 고려 X

#### 지역 교체
- **현재 수행 중인 프로세스에게 할당된 프레임 내에서만** 교체 대상을 선정하는 방안
- 지역교체는 프로세스마다 페이지 프레임을 미리 할당하는 것을 전제로 함


## 스레싱

![](https://i.imgur.com/2ZccYIP.png)

**스레싱**

- 페이지 부재가 발생하면 OS내 trap이 발생함
- 보통 OS는 I/O 작업을 하러가면 CPU의 낭비를 방지하기 위해 CPU 사용률 감소시킴 (I/O 작업이 완료되었다고하면 그때 다시 CPU 작업시작 -> Event 처리 방식과 유사)
- **문제는 프로세스마다 메모리가 너무 적게 할당되어 페이지 부재가 아주 빈번히 발생하면 I/O 처리량만 늘어남으로써 CPU 사용률이 낮아지는 문제가 발생
- 이러한 현상을 **스레싱**
    - 메모리에 동시에 올라가 있는 프로세스의 수가 많아져서 각 프로세스가 갖는 메모리 용량이 적어지면!!!
    - 프로세스에게 페이지가 너무 적게 할당되어 잦은 페이지 부재가 발생할 수 있음
    - 이럼 I/O 작업을 해야하므로, CPU 사용률이 줄어드는 것

**더 큰 문제**
- OS는 CPU 이용률이 낮아지면 프로그램을 메모리에 더 올려야한다고 판단하기 때문에 프로그램을 계속해서 올림
- 즉, 프로그램이 계속 메모리가 올라갈 수록 페이지 부재가 더 자주 발생하여, 페이지 교체하고 I/O 작업하느라 CPU는 할 일이 없어서 한가한 상황이 되어버림

정리하면 멀티 프로그래밍 정도와 CPU 이용률의 상간관계가 존재함
- 메모리 내에 프로세스의 수를 증가시키면 CPU 이용률이 이에 비례해서 증가하게 되는데, 어느 한계치를 넘어서면 CPU 이용률이 급격하게 떨어지게 됨 -> 이게 스레싱

따라서, 스레싱이 발생하지 않도록 하면서 CPU 이용률을 최대한 높일 수 있도록 멀티 프로그래밍 정도를 조절해야 함
- 멀티 프로그래밍 정도를 조절하는 알고리즘 크게 두 가지로 나누는데
	- 워킹셋 알고리즘
		- 집중적으로 참조되는 페이지들을 집합으로 묶어서 한번에 메모리에 올리고, 디스크에 내리는 방식
		- 집합으로 묶을 워킹셋 윈도우를 사용하여 각 프로세스가 처리에 필요한 페이지를 한번에 내리고 한번에 올리는 방식임
		- 이는 **프로세스가 너무 많으면 워킹셋에 의해 메모리에 올리는 프로세스의 개수를 제한함으로써 멀티 프로그래밍 정도를 줄임
		- 반면 프레임이 남으면 프로세스의 워킹 셋을 한번에 올려 멀티프로그래밍 정도를 증가시킴
	- 페이지 부재 빈도 알고리즘
		- 프로세스의 페이지 부재율을 주기적으로 조사하고 이 값에 근거해서 각 프로세스에 할당할 메모리 양을 동적으로 조절
		- 어떤 프로세스의 페이지 부재율이 시스템에서 미리 정해놓은 상한값을 넘게되면 이 프로세스에 할당된 프레임의 수를 판단하여 프레임을 추가로 할당함
		- 반면 프로세스의 페이지 부재율이 하한값 이하로 떨어지면 이 프로세스에게 필요 이상으로 많은 프레임이 할당된 것으로 간주해 할당된 프레임의 수를 줄이는 알고리즘

